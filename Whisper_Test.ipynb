{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "import moviepy\n",
    "from moviepy import VideoFileClip\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#place of video on device\n",
    "video_input_path= 'video.mp4'\n",
    "#folder where sound clips can be saved\n",
    "audio_output_path= './audio/'\n",
    "#In seconds\n",
    "length_of_clip = 5\n",
    "#transcript save location\n",
    "text_path = 'text_from_video.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "print(number_of_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2022-01-26T14:49:30.000000Z'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 34, 'fps': 30.0, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2022-01-26T14:49:30.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 01/26/2022.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'creation_time': '2022-01-26T14:49:30.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 01/26/2022.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1243.08, 'bitrate': 166, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 34, 'video_fps': 30.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 1243.08, 'video_n_frames': 37292}\n",
      "/Users/lszlpotyondi/miniconda3/lib/python3.9/site-packages/imageio_ffmpeg/binaries/ffmpeg-macos-aarch64-v7.1 -i video.mp4 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in ./audio/000.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./audio/001.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'mp42', 'minor_version': '0', 'compatible_brands': 'isommp42', 'creation_time': '2022-01-26T14:49:30.000000Z'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [640, 360], 'bitrate': 34, 'fps': 30.0, 'codec_name': 'h264', 'profile': '(Main)', 'metadata': {'Metadata': '', 'creation_time': '2022-01-26T14:49:30.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 01/26/2022.', 'vendor_id': '[0][0][0][0]'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': 'eng', 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'creation_time': '2022-01-26T14:49:30.000000Z', 'handler_name': 'ISO Media file produced by Google Inc. Created on: 01/26/2022.', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 1243.08, 'bitrate': 166, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(Main)', 'video_size': [640, 360], 'video_bitrate': 34, 'video_fps': 30.0, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 1243.08, 'video_n_frames': 37292}\n",
      "/Users/lszlpotyondi/miniconda3/lib/python3.9/site-packages/imageio_ffmpeg/binaries/ffmpeg-macos-aarch64-v7.1 -ss 7.000000 -i video.mp4 -ss 1.000000 -loglevel error -f image2pipe -vf scale=640:360 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in ./audio/002.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#reading in video, formatting for model use (25MB or smaller clips neccesary)\n",
    "\n",
    "clip = VideoFileClip(video_input_path)\n",
    "duration = clip.duration\n",
    "number_of_clips= int(duration/length_of_clip)+1\n",
    "\n",
    "\n",
    "number_of_clips=3\n",
    "\n",
    "\n",
    "for i in range(number_of_clips):\n",
    "\n",
    "    start_of_clip= i*length_of_clip-2\n",
    "    end_of_clip= i*length_of_clip+length_of_clip+2\n",
    "\n",
    "    if start_of_clip<0:\n",
    "        start_of_clip=0\n",
    "    if end_of_clip > duration:\n",
    "        end_of_clip=duration\n",
    "    \n",
    "    str_i = \"%03d\" % i\n",
    "    \n",
    "\n",
    "    subclip= clip.subclipped(start_of_clip,end_of_clip)\n",
    "    subclip_path= audio_output_path+str_i+'.mp3'\n",
    "    subclip.audio.write_audiofile(\n",
    "        subclip_path,\n",
    "        bitrate = \"128k\" # or it could be \"192k\" or \"320k\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=os.listdir(audio_output_path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lszlpotyondi/miniconda3/lib/python3.9/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: hu, Clip: 000.mp3\n",
      "Ebben a videóban egy viszonylag friss cikkre fogok reagálni, szoftverfejlesztő kezdő fizikusokkal.\n",
      "Detected language: hu, Clip: 001.mp3\n",
      "Cikkre fogok reagálni, szoftverfejlesztő kezdő fizetésekkel kapcsolatban.\n",
      "Detected language: tr, Clip: 002.mp3\n",
      "Müzik\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = whisper.load_model(\"turbo\")\n",
    "text = ''\n",
    "\n",
    "for name in file_list:\n",
    "    if not name.startswith('.') and os.path.isfile(os.path.join(audio_output_path, name)):\n",
    "        # load audio and pad/trim it to fit 30 seconds\n",
    "        audio = whisper.load_audio(audio_output_path+name)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "        # make log-Mel spectrogram and move to the same device as the model\n",
    "        mel = whisper.log_mel_spectrogram(audio=audio, n_mels=128).to(model.device)\n",
    "\n",
    "        # detect the spoken language\n",
    "        _, probs = model.detect_language(mel)\n",
    "        print(f\"Detected language: {max(probs, key=probs.get)}, Clip: {name}\")\n",
    "\n",
    "        # decode the audio\n",
    "        options = whisper.DecodingOptions()\n",
    "        result = whisper.decode(model, mel, options)\n",
    "\n",
    "        # print the recognized text\n",
    "        text += '\\n'\n",
    "        text += result.text\n",
    "        print(result.text)\n",
    "\n",
    "#with open(text_path, mode='wt') as f:\n",
    "    #f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(text_path,'r')\n",
    "\n",
    "input_text= f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "texts = text_splitter.create_documents([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=\"YOUR_API_KEY\",\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=openai_ef,\n",
    "    collection_name=\"local-rag\"\n",
    ")\n",
    "print(\"Vector database created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
